{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1625a9-d78e-4e88-8df6-d85e8212ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Web scraping is an automatic method to obtain data from websites.\n",
    "Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database\n",
    "so that it can be used in various applications.\n",
    "\n",
    "Usage:\n",
    "1. Market Research\n",
    "2. Sentimental Analysis\n",
    "3. Email Marketing (collect email ids and send promotional and marketing Emails) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9504f2e-db0b-490f-8a7f-42c86ab7eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q2. What are the different methods used for Web Scraping?\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Methods for Web Scraping\n",
    "1. HTML Parsing\n",
    "2. DOM Parsing\n",
    "3. Google Sheets\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f51415a-7411-4782-937f-bb931f2ed388",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Beautiful Soup is a Python package for parsing HTML and XML documents.\n",
    "It is used to pull particular content from a webpage, remove the HTML markup, and save the information.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c6c4cc-b341-47c9-ad41-ba07fc803c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q4. Why is flask used in this Web Scraping project?\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Flask is a lightweight framework so it is used to build API and Websites for web scrapping project\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f50358-4f9b-42e7-bf23-784c6c1f7726",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "1. CodePipeline\n",
    "AWS CodePipeline is a fully managed continuous delivery service that helps to automate release pipelines for fast and reliable application and infrastructure updates.\n",
    "\n",
    "2. Elastic Beanstock\n",
    "Elastic Beanstalk is a service for deploying and scaling web applications and services.\n",
    "Upload your code and Elastic Beanstalk automatically handles the deploymentâ€”from capacity provisioning, load balancing, and auto scaling to application health monitoring.\n",
    "\n",
    "CodePipeline is used to deploy to an Elastic Beanstalk environment. \n",
    "Once the Elastic Beanstalk environment is set up, the source repository (e.g. Github) can be configured and then the CodePipeline pipeline is configured.\n",
    "Ultimately, the deployment service will be Elastic Beanstalk, and each deployment will be to the Elastic Beanstalk environment.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
